\section{Related Work}
\label{sec:related_works}
This chapter provides a quick overview of the literature on unsupervised learning approaches for point clouds as well as variety of local feature extraction techniques on point clouds.

\vspace{5mm}


Since deep learning methods can directly process point clouds, feature learning for 3D objects has advanced significantly in the recent years. By independently learning every point in the point cloud and combining point characteristics with permutation invariant operations, PointNet \cite{qi2017pointnet} and Deep Sets \cite{zaheer2017deep} were the pioneers in the field to handle unordered and unstructured 3D points. Both \cite{qi2017pointnet} and \cite{zaheer2017deep} were important developments in deep learning for handling unordered data. \cite{qi2017pointnet} was designed particularly for 3D point cloud analysis, while \cite{zaheer2017deep} provides a broader framework for feature learning that is permutation invariant and could be extrapolated to graphs and sequences. These methods were capable to generate promising results. But it had limitations in learning the local features and hence needs further improvement to make them more scalable across different applications. PointNet++ \cite{qi2017pointnet++} enhances \cite{qi2017pointnet} by introducing a hierarchical feature learning technique that functions directly in a metric space. It has the ability to acquire knowledge at varying levels, the hierarchical arrangement of point clouds into nested partitions and combining sampling techniques that capture complex spatial relationships while maintaining permutation invariance. 


\vspace{5mm}

\cite{wang2019dynamic}  designed a \ac{DGCNN} architecture specifically for point cloud data. Its main contribution is to enable more efficient feature learning by dynamically building graph structures from point clouds based on local geometric correlations. But on the other hand, dynamic graph creation adds more computational complexity and might necessitate precise hyperparameter tuning. Although PointCNN \cite{li2018pointcnn} demonstrated state-of-the-art performance on a range of point cloud applications, the x-transformation adds to computational overhead and may restrict scalability, particularly when working with large-scale datasets.  But it provided a  permutation-invariant procedure that changes the orientation of point clouds to a canonical orientation enabling the use of standard convolutional operations. A deep learning architecture that directly operates on three-dimensional point clouds was introduced in \cite{wu2019deep}. 

\vspace{5mm}

The development of techniques for unsupervised representation learning on point clouds has been the focus of several works in the literature. These methods can be broadly classified as discriminative \cite{grill2020bootstrap} or generative \cite{sarmad2019rl}. The majority of techniques include autoencoding \cite{yang2018foldingnet} or \ac{GAN}s \cite{sarmad2019rl}.  Their primary method of operation is using an encoder to convert an input point cloud into a global latent representation \cite{rao2020global}, \cite{shi2020unsupervised}, or a latent distribution in the variational case \cite{hassani2019unsupervised}, \cite{han2019multi}, after which a decoder tries to reconstruct the input. High-level structural features can be effectively modeled by generative models. Nevertheless, a lot of these methods often work under the premise that every 3D item in a category has the same pose \cite{sanghi2020info3d}. Because of this assumption, these methods are sensitive to translation and rotation operations. Discriminative models, unlike generative methods, are trained to distinguish between data augmentations. It is seen that these methods produce good quality latent representations. Contrastive methods \cite{rao2020global}, \cite{sanghi2020info3d} have demonstrated impressive outcomes in recent unsupervised point cloud representation learning approaches, among discriminative models. Through data augmentation and comparison, contrastive approaches also enable the generation of rotation invariant representations \cite{poursaeed2020self}. Predicting a representation that is distant from the negative examples and closer to the positive ones is a crucial concept in contrastive learning \cite{chen2020simple}. But in order to perform better, these algorithms need a large number of negative examples to compare and rely largely on the selection of the negative samples and how they are paired alongside the positives \cite{grill2020bootstrap}, \cite{chen2021exploring}. Such an unsupervised method is typically computationally expensive and requires careful handling of the negative pairs, which can be achieved by relying on memory banks, huge batch sizes, or tailored mining strategies.\cite{grill2020bootstrap}

\vspace{5mm}

\cite{liu2019relation} presented a \ac{CNN} that incorporates relation-aware convolutional procedures which capture both local and global geometric relationships inside point clouds. Position-adaptive feature learning was the primary innovation of PAConv\cite{xu2021paconv}, which is the dynamic assembly of convolutional kernels based on local geometric structures. By using this method, the network performed better in segmentation and classification tasks by improving its capacity to detect intricate geometric patterns and variances within point clouds. The main contribution of AdaptConv \cite{zhou2021adaptive} was the inclusion of adaptive graph convolutional operations, which dynamically modify convolutional kernels receptive fields according to the point clouds local geometric characteristics. Because of the flexibility, the network can better execute tasks like segmentation and classification by capturing local and global geometric data. Convolutional operations adaptive nature might add more computational complexity. Moreover, the quality of local geometric information and intricacy of the point cloud may have a significant influence on the adaptive graph convolutional approach's efficacy, which may affect how well it performs in various datasets and applications. 

\vspace{5mm}

In \cite{sun2021quadratic}, a novel approach to encoding point clouds in three-dimensional (3D) space was presented. This method makes use of quadratic terms to more accurately describe local surface geometry. The capacity of the model to identify surface curvature and shape fluctuations is enhanced by the addition of quadratic components. As a result of including higher-order geometric information in the feature representations the discriminative ability of deep learning models were improved for point cloud segmentation and object classification tasks.  \cite{ding2021point} described how perturbation learning can improve the resolution of point cloud data. Its ability to generate high-resolution point clouds with improved geometric details is useful for 3D reconstruction and object detection applications. By using perturbation learning, the method can effectively capture fine-grained features and surface details, improving the overall quality of the unsampled point clouds. Also, the method can be applied to a variety of point cloud datasets because it is flexible and does not require any particular surface representations.  A new technique for geometric feature preservation in \ac{LiDAR} point cloud compression was reported by \cite{song2021layer}. This framework uses a layer-wise geometry aggregation approach to achieve lossless compression, which ensures that no information is lost across multiple layers of the point cloud.  The computational complexity of combining and evaluating geometric data across multiple levels could be a drawback. As more input point cloud data becomes available, this complexity might increase. \cite{zhao2021transformer3d} provided an innovative technique for improving the performance of 3D object detection by using transformer networks to refine votes. It combines and refines votes from different parts of the point cloud to enhance object recognition. This method increased accuracy and robustness in 3D object identification tasks. While these approaches were remarkably successful, in order to do feature learning, they need supervised data. Point cloud models are difficult to implement in novel real-world scenarios where labelled data is hard to come by due to their reliance on annotation. Therefore, its critical to devise strategies for lowering the quality of annotated samples needed to complete deep learning-based point cloud interpretation tasks with the necessary performance\cite{mei2022unsupervised}.
\cleardoublepage